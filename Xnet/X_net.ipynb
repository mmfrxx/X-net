{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X-net.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qHK9rJIgzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHIno0epKGGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4epxM-5KW0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kaCEIQMKjR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CplUx2zuMlch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma16FFCjMqLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd content\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5W2HVdsKqGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d nih-chest-xrays/sample -p /content\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrs8wRzFK3Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip sample.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2AyrYUQSUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zZ605QTW5Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "shutil.move(\"/content/sample.zip\", \"/content/images\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4biPpvVFXaUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(10,13):\n",
        "#  shutil.move(\"/content/images_0\"+str(i)+\".zip\",\"/content/images\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaEMA08RXr7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23y_m9KBXzcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QPjxVjjoKJt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llr4fAKjYBCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHE9lw6hYVvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpzpwlKJn-oa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ..\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRF8pI0PYaWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from skimage import transform, io\n",
        "from torchvision import transforms,utils\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from itertools import chain\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.backends.cudnn as cudnn \n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS4T37gDcegm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChestDataset(Dataset):\n",
        "  def __init__(self, image_names, labels, transform):\n",
        "    img_names = []\n",
        "    for name in image_names:\n",
        "      img_names.append(name)\n",
        "    self.image_names = img_names\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "    image_name = self.image_names[index]\n",
        "    image = Image.open(image_name).convert('L')\n",
        "    label = self.labels[index]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    sample = {'image': image, 'label': torch.tensor(np.vstack(label).astype(np.float), dtype = torch.float32)} \n",
        "    return sample\n",
        "  \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcF1HHkf9ktD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_classes = 13\n",
        "CLASS_NAMES = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
        "IMG_DIR = \"./images/images/\"\n",
        "CSV_FILE = \"sample_labels.csv\"\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1DxZdT1_KOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_xray_df = pd.read_csv(CSV_FILE)\n",
        "all_image_paths = {os.path.basename(x): x for x in glob(os.path.join(IMG_DIR, '*.png'))}\n",
        "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
        "all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
        "all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
        "all_labels = [x for x in all_labels if len(x)>0]\n",
        "\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
        "\n",
        "for c_label in all_labels:\n",
        "  if len(c_label)>1: # leave out empty labels\n",
        "    all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n",
        "\n",
        "MIN_CASES = 20\n",
        "all_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\n",
        "all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
        "print(len(all_xray_df['path']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppB2i1aeihyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,test_x,train_y, test_y = train_test_split(all_xray_df['path'].to_numpy(), all_xray_df['disease_vec'].to_numpy(),\n",
        "                                   test_size = 0.40, \n",
        "                                   random_state = 2018)\n",
        "test_x, val_x, test_y, val_y = train_test_split(test_x,test_y ,\n",
        "                                   test_size = 0.50, \n",
        "                                   random_state = 2018)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti8HruOClUbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = ChestDataset(image_names = test_x, labels=test_y, \n",
        "                    transform = transforms.Compose([transforms.Scale(256), \n",
        "                    transforms.Grayscale(),transforms.ToTensor(),transforms.Normalize(mean = [0.485], std = [0.229])]))\n",
        "test_loader = DataLoader(test, batch_size = 1, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOklNRfylVXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = ChestDataset(train_x, train_y, \n",
        "                    transform = transforms.Compose([transforms.Scale(256),\n",
        "                                                    transforms.Grayscale(), transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean = [0.485], std = [0.229])]))\n",
        "\n",
        "train_loader = DataLoader(train, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgHy1O0l1mM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = ChestDataset(val_x, val_y, \n",
        "                    transform = transforms.Compose([transforms.Scale(256),\n",
        "                    transforms.Grayscale(), transforms.ToTensor(),\n",
        "                                                    transforms.Normalize(mean = [0.485], std = [0.229])]))\n",
        "\n",
        "valid_loader = DataLoader(valid, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOvuUG8BRUqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Xnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Xnet,self).__init__()\n",
        "    self.fc1 = nn.Linear(256*256,number_of_classes)\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1, 256*256)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = nn.Sigmoid()(x)\n",
        "    return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cA99_hi2mjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DEFINE THE NETWORK\n",
        "class Xnet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Xnet,self).__init__() \n",
        "    self.conv1 = nn.Conv2d(1,64,kernel_size = 3, padding = 1)                     #1 x 256 x 256 > 64 x 256 x 256\n",
        "    self.batch_norm1 = nn.BatchNorm2d(64)                                         #BN1 = 64                                                \n",
        "    self.pool = nn.MaxPool2d(2,2)                                                 # 64 x 128 x 128 \n",
        "    self.conv2 = nn.Conv2d(64,128, kernel_size =3, padding =1)                    # 128 x 128 x 128\n",
        "    self.batch_norm2 = nn.BatchNorm2d(128)                                        # bn2 = 128\n",
        "    self.conv3 = nn.Conv2d(128,256, kernel_size = 3, padding = 1)                 # 256 x 128 x 128\n",
        "    self.batch_norm3 = nn.BatchNorm2d(256) \n",
        "    self.conv4 = nn.Conv2d(256,512, kernel_size = 3, padding = 1)\n",
        "    self.batch_norm4 = nn.BatchNorm2d(512) \n",
        "    self.conv5 = nn.Conv2d(512,512, kernel_size = 3, padding = 1)\n",
        "    self.conv6 = nn.Conv2d(512,256, kernel_size = 3, padding = 1)\n",
        "    self.conv7 = nn.Conv2d(256,128, kernel_size = 3, padding = 1)\n",
        "    self.conv8 = nn.Conv2d(128,128,kernel_size = 3, padding = 1)\n",
        "    self.conv9 = nn.Conv2d(128,256,kernel_size = 3, padding = 1)\n",
        "    self.conv10 = nn.Conv2d(256, 512, kernel_size = 3, padding =1)\n",
        "    self.conv11 = nn.Conv2d(512,512, kernel_size = 3, padding = 1)\n",
        "    self.conv12 = nn.Conv2d(512,256, kernel_size = 3, padding = 1)\n",
        "    self.conv13 = nn.Conv2d(256,128, kernel_size = 3, padding = 1)\n",
        "    self.conv14 = nn.Conv2d(128,64, kernel_size =3, padding = 1)\n",
        "    self.conv15 = nn.Conv2d(64, number_of_classes, kernel_size = 1)\n",
        "    self.fc1 = nn.Linear(13*256*256, 64)\n",
        "    self.fc2 = nn.Linear(64, number_of_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    act1 = F.relu(self.batch_norm1(self.conv1(x)))          #64 x 256 x 256\n",
        "    x = self.pool(act1)                                     #64 x 128 x 128\n",
        "    act2 = F.relu(self.batch_norm2(self.conv2(x)))          #128 x 128 x 128\n",
        "    x = self.pool(act2)                                     #128 x 64 x 64\n",
        "    act_3 = F.relu(self.batch_norm3(self.conv3(x)))         #256 x 64 x 64\n",
        "    x = self.pool(act_3)                                    #256 x 32 x 32\n",
        "    x = F.relu(self.batch_norm4(self.conv4(x)))   #512 x 32 x 32\n",
        "    x = F.relu(self.batch_norm4(self.conv5(x)))   #512 x 32 x 32\n",
        "    x = F.upsample(x, size = 64)   #6\n",
        "    x = F.relu(self.batch_norm3(self.conv6(x)))   #256 x 64 x 64    \n",
        "    x = x.add(act_3)    \n",
        "    x = F.upsample(x, size = 128)                 #256 x 128 x 128\n",
        "    x = F.relu(self.batch_norm3(self.conv7(x)))   #128 x 128 x 128\n",
        "    x = x.add(act2)    \n",
        "    act_8 = F.relu(self.batch_norm2(self.conv8(x))) #128 x 128 x 128\n",
        "    x = self.pool(act_8)                            #128 x 64 x 64\n",
        "    act_9 = F.relu(self.batch_norm3(self.conv9(x))) #256 x 64 x 64\n",
        "    x = self.pool(act_9)                            #256 x 32 x 32\n",
        "    x = F.relu(self.batch_norm4(self.conv10(x)))    #512 x 32 x 32\n",
        "    x = F.relu(self.batch_norm4(self.conv11(x)))    #512 x 32 x 32    \n",
        "    x = F.upsample(x, size = 64)                    #512 x 64 x 64\n",
        "    x = F.relu(self.batch_norm3(self.conv12(x)))    #256 x 64 x 64\n",
        "    x = x.add(act_9)    \n",
        "    x = F.upsample(x, size = 128)                   #256 x 128 x 128 \n",
        "    x = F.relu(self.batch_norm2(self.conv13(x)))    #128 x 128 x 128\n",
        "    x = x.add(act_8)    \n",
        "    x = F.upsample(x, size = 256)                   #128 x 256 x 256\n",
        "    x = F.relu(self.batch_norm1(self.conv14(x)))    #64 x 256 x 256\n",
        "    x = x.add(act1)\n",
        "    x = self.conv15(x)                              #13 x 256 x 256\n",
        "    x = x.view(-1,13*256*256)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = nn.Sigmoid(self.fc2(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxImvfqxo65K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Xnet()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "#criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "criterion = nn.BCELoss(reduction='sum')\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-4,weight_decay = 0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxqolXgT2gPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "best_acc = 0.0\n",
        "best_model =  model.state_dict()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  r_loss = 0\n",
        "  train_correct = 0\n",
        "  r_total = 0 \n",
        "  model.train()\n",
        "  for data in train_loader:\n",
        "    \n",
        "    inputs = data['image'].to(device)\n",
        "    labels= data['label'].to(device).squeeze(dim = 2)\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    labels = labels.type(torch.FloatTensor)\n",
        "    outputs =outputs.type(torch.FloatTensor)\n",
        "    \n",
        "    loss = criterion(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    outputs = torch.round(outputs)\n",
        "    #print(labels.size())\n",
        "    \n",
        "    labels = labels.type(torch.LongTensor)\n",
        "    outputs =outputs.type(torch.LongTensor)\n",
        "    \n",
        "    train_correct += torch.sum(outputs == labels).item()\n",
        "    #print(\"pred\")\n",
        "    #print(prediction)\n",
        "    #print(\"lab\")\n",
        "    #print(labels[0])\n",
        "    #print(torch.sum(outputs == labels).item())\n",
        "    r_loss += loss.item()\n",
        "    r_total += labels.size(0)\n",
        "    #print(labels.size())\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    val_losses = 0\n",
        "    val_correct = 0\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    \n",
        "    for data in valid_loader:\n",
        "      inputs = data['image'].to(device)\n",
        "      labels= data['label'].to(device).squeeze(dim = 2)\n",
        "      outputs = model(inputs)\n",
        "      \n",
        "      labels = labels.type(torch.FloatTensor)\n",
        "      outputs =outputs.type(torch.FloatTensor)\n",
        "      \n",
        "      val_loss = criterion(outputs,labels)\n",
        "      val_losses += val_loss.item()\n",
        "      \n",
        "      outputs = torch.round(outputs)\n",
        "      \n",
        "      labels = labels.type(torch.LongTensor)\n",
        "      outputs =outputs.type(torch.LongTensor)\n",
        "      val_correct += torch.sum(outputs ==labels).item()\n",
        "      total += labels.size(0)\n",
        "      \n",
        "  r_loss = r_loss/total\n",
        "  train_correct = train_correct/r_total/number_of_classes\n",
        "  \n",
        "  val_loss = val_losses/ total\n",
        "  val_correct = val_correct/ total/number_of_classes\n",
        "  \n",
        "  if val_correct > best_acc:\n",
        "    bect_acc = val_correct\n",
        "    best_model = model.state_dict()\n",
        "  \n",
        "       \n",
        "  print(\"Epoch:\" + str(epoch) +\". Training loss:{: .3f}.  Train correct: {: .3f}\".format(r_loss, train_correct))\n",
        "  print('Validation loss: {: .3f}, {: .3f}'.format(val_loss, val_correct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di_TXtyhAbku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir models\n",
        "torch.save(best_model, \"./models/model\" + str(20) + \".pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTEZ0ruUuA4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing process\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for data in test_loader:\n",
        "    inputs = data['image'].to(device)\n",
        "    labels= data['label'].to(device).squeeze(dim = 2)\n",
        "    outputs = model(inputs)\n",
        "    outputs = torch.round(outputs)\n",
        "    \n",
        "    labels = labels.type(torch.LongTensor)\n",
        "    outputs =outputs.type(torch.LongTensor)\n",
        "    \n",
        "    total +=labels.size(0)\n",
        "    correct +=torch.sum(outputs == labels).item()\n",
        "print(\"Accuracy of the network is %f %%\" %(correct*100/number_of_classes/ total))\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyalfwhbJMSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}